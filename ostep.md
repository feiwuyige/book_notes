[TOC]

# OSTEP

## 第一部分 虚拟化

### 第四章 抽象：进程

1. 理解进程的关键在于理解它的**机器状态（state machine）**，即程序在运行时可以读取或更新的内容。
   * 内存：程序的指令是存放在内存中的，进程读取和写入的数据也在内存中。进程可以访问的内存称为**地址空间（address space）。**
   * 寄存器：PC指针，栈基址 rbp，栈顶指针 rsp
   * 磁盘：程序可能会修改磁盘中的内容，比如当前程序打开的文件。
2. 进程api：操作系统是对硬件的抽象，同时在应用视角应该是给应用程序提供服务，也就是 api，所以显然操作系统中应该有一组处理进程的 api：
   * 创建进程(create)：创建一个新的进程。
   * 销毁进程(destroy)：如果进程不能正常退出，应当可以关闭。
   * 等待进程(wait)：有的时候进程之间需要同步，所以可能需要某一个进程等待另一个进程完成。
   * 其他控制(miscellanous control)：比如可能将某个进程暂时挂起，然后再恢复。
   * 状态(statu)：获取当前进程的相关信息，比如占用了多少内存。
3. 进程创建的步骤：
   * 程序的指令和数据只有在内存中才可以执行，而程序就是一个存放在磁盘上的文件，所以**首先一定要先将程序从磁盘加载到内存中**。
   * 为程序的运行时栈分配内存。
   * 为程序的堆分配一些内存。
   * 其他初始化任务，比如打开进程的文件描述符，将0 1 2绑定到标准输入、标准输出、标准错误输出。
   * 启动程序，将 CPU 的控制权转移到新创建的进程中去。
4. 进程的状态：
   * 运行：正在占用 CPU
   * 就绪：等待调度，可以去 CPU 上执行指令
   * 阻塞：因为某些原因需要等待某些操作完成，比如 I / O，此时不需要 CPU ，所以让 CPU 调度其他程序，从而提高效率。

### 第五章 插叙：进程API

1. * `fork`
   * `execve`
   * `waitpid`
   * `_exit`

### 第六章 机制：受限直接执行

1. 通过对 `CPU` 进行时分共享来实现虚拟化，即运行一个进程一段时间以后切换为另一个进程进行运行。要实现这样的机制有如下挑战：

   * 不增加系统开销，实现高性能
   * 对 `CPU` 的控制权，操作系统对资源进行管理，所以理应具有资源的控制权

2. 为了保证性能，所以采用**直接执行**的方式，就是将进程直接放在物理 `CPU` 上进行程序执行，这样的优势是**快速**，但是进程肯定要进行相关的其他操作，比如I/O，这些操作应当是有限制的，换句话说，应当由操作系统来进行管理，比如进程能否访问这个文件，所以硬件通过提供不同的执行模式来协助操作系统。

   * 用户模式：应用程序不能完全访问硬件资源。
   * 内核模式：操作系统可以访问机器的全部资源，并且提供陷入内核和从陷阱返回到用户模式程序的方式。

   当用户希望执行特权操作时，我们可以使用**系统调用**，他允许内核向用户程序暴露某些关键功能。要执行系统调用，程序必须执行特殊的陷阱（trap）指令，该指令跳入内核同时将特权级别提升到内核模式。执行完毕后，操作系统调用一个特殊的从陷阱返回（return-from-trap）指令，该指令返回到发起调用的用户程序中，同时将特权级别降低，回到用户模式。

3. 内核通过在启动时设置陷阱表（trap table）来实现陷阱指令的跳转，即告诉硬件在发生某些异常事件时要运行哪些代码。一旦硬件被通知，它就会记住这些处理程序的位置，直到下一次重新启动机器，并且硬件知道在发生系统调用和其他异常事件时要做什么（即跳转到哪段代码）。
4. 为了进行进程切换，操作系统一定要获取 `CPU` 的控制权，也就是说必须在 `CPU` 上执行操作系统的代码，但是此时用户的进程正在执行，所以有以下机制来达到目标：
   * 协作方式：等待系统调用，进程执行系统调用时，将 `CPU` 的控制权交给操作系统。或者应用程序执行某些非法操作。（死循环，不调用系统调用怎么办？
   * 非协作方式：操作系统进行控制，利用时钟中断使得操作系统重新获取 `CPU` 的控制权。（中断向量表，在启动时告诉硬件哪些代码在发生时钟中断时运行）
5. 无论以哪一种方式，当操作系统获得 `CPU` 的控制权时，将使用调度程序来决定运行哪一个进程，如果决定进行切换，操作系统就会进行**上下文切换**，即为当前正在执行的进程保存一些寄存器的值到内核栈，并为即将执行的进程恢复一些寄存器的值（从它的内核栈）。
6. 中断处理执行程序在执行时、或者系统调用执行时发生了中断怎么办？操作系统应该设计类似的机制来进行处理，即**并发**模块。

### 第七章 进程调度：介绍

1. 要思考的关键问题：
   * 如何开发一个考虑调度策略的基本框架？
   * 有哪些关键假设？
   * 哪些指标非常重要？
   * 哪些基本方法已经在早期的系统中使用？
2. 调度指标：
   * 周转时间：$$T_{周转时间} = T_{完成时间} - T_{到达时间}$$
   * 响应时间：$$T_{响应时间} = T_{首次运行} - T_{到达时间}$$
   * 公平性：是否每一个进程在调度的过程中被公平对待。
3. 调度算法：
   * `FIFO`：可能会出现护航效应，一些好事较少的潜在资源消费者被排在重量级的资源消费者之后。即前面的任务需要很长时间才能执行完毕，从而导致整体的周转时间变多。
   * `SJF` ：先运行最短的任务，然后是次短的任务，如此下去。但是任务肯定不会同时到达，而是随即到达，该策略不允许抢占，那么也会出现护航效应。
   * `STCF`：最短完成时间优先，即向 `SJF` 添加抢占。
   * `RR` ：轮转调度，在一个时间片内运行一个工作，然后切换到运行队列中的下一个任务。时间片长度必须是**时钟中断周期的倍数**。

### 第八章 调度：多级反馈队列

1. 实际上，我们对于进程的执行时间一无所知，所以我们需要在没有工作长度的先验知识的前提下，设计一个能同时减少响应时间和周转时间的调度程序。**所以我们要从历史中学习，利用历史去预测未来**。计算机系统中还有很多地方是这样的思想，比如硬件的分支预测，缓存算法等。
2. MLFQ调度算法中存在很多队列，每个队列有不同的优先级，同一时间一个工作只能存在于一个优先级队列中，它的基本规则：

   * 运行优先级较高的队列中的工作
   * 同一优先级队列中的工作，使用轮转的方式进行运行

   所以该调度算法的关键在于优先级的确定，它采用一种从历史学习的方法，比如如果一个进程不断的放弃CPU去等待键盘输入，那么该进程可能会是一个交互程序，需要响应时间，所以其优先级较高；如果一个进程一直占用CPU而没有其他操作，那可能它的优先级就会很低。

3. 由于是从历史过程去预测未来，所以我们一定要有某些机制，如：

   * 改变一个进程的优先级：我们使用的策略是当一个进程加入时，总是在优先级最高的队列，如果它的时间片用完，则进入下一个低优先级的队列，如果在它的时间片用完之前主动放弃CPU（可能是一个交互性工作，保证响应时间），则使他的优先级保持不变。（如果采用这样的策略，低优先级队列中的进程可能永远得不到执行；还有一些程序愚弄调度程序，使用99%时间片以后主动释放CPU从而使得自己一直在一个较高的优先级）
   * 为了解决**饥饿**问题，我们可以周期性提升所有工作的优先级，即经过一段时间以后，就将系统中的所有工作都加入到高优先级队列，该策略的关键就在于周期性时间的确认，确认一个合适的时间十分重要。
   * 为了避免愚弄调度程序，可以使用一个更好的计时方式，我们给每一个优先级队列中的进程都分配固定的时间配额，一旦用完了该时间配额，不管主动放弃了多少次，都将其加入到一个低优先级队列中。

### 第九章 调度：比例份额

1. 基本思想是：调度程序的最终目标是确保每一个工作可以获得一定比例的CPU时间，而不是优化周转时间和响应时间。所以关键在于如何设计调度程序来按照比例分配CPU。
2. 彩票调度：比如两个进程A和B，A拥有75张彩票，B拥有25张彩票，那么我们就希望A占75%的CPU时间，B占25%的CPU时间，我们通过产生一个1-100的随机数，如果随机数在1-75运行A否则运行B来做到这一点。
3. 步长调度：根据每个工作所占的份额来求取一个步长，再对于每一个工作记录它们的行程值，每次选择最小的行程值进程，然后进行执行，执行完加上一个它自己的步长。

### 第十章 多处理器调度（高级）

1. 缓存一致性：每个CPU都有自己的缓存，如果一个CPU上的进程更新了数据还没有写入内存，而另一个CPU上的进程就进行读取就会出现缓存不一致问题。**硬件提供了这个问题的基本解决方案，通过监控内存访问，硬件可以保证获得正确的数据，并保证共享内存的唯一性**。比如在基于总线的系统中，一种方式是使用总线窥探（bus snooping）。每个缓存都通过监听链接所有缓存和内存的总线，来发现内存访问。如果CPU发现对它放在缓存中的数据的更新，会作废（invalidate）本地副本（从缓存中移除），或更新（update）它（修改为新值）。
2. 同步：跨CPU访问，尤其是写入共享数据或数据结构时，需要使用互斥原语来保证正确性，比如锁。
3. 缓存亲和度：一个进程在CPU上运行会缓存一些数据，如果下次还在这个CPU上就会执行的很快，如果在其他的CPU上就执行的很慢。
4. 两种基本模式：
   * 单队列调度：将所有的进程放在一个队列中，然后依次放入不同的CPU中进行执行。这种方式对于共享资源的访问（队列）会出现竞争，可扩展性较差，且每个任务在哪个CPU 上执行是随机的，缓存亲和度较差。
   * 多队列调度：每一个CPU都有一个自己的调度队列，然后将这个调度队列中的任务放在对应的CPU上进行执行。可扩展性较好，缓存亲和度好，但是容易出现负载不均衡，比如某个CPU上的任务执行完毕了，那么这个CPU上就没有任务在执行，浪费了资源，可以使用**任务窃取**来从其他队列中把一些任务移动到该队列来避免该问题，但是什么时候去观察其他队列中的任务情况需要进行斟酌。
5. Linux多处理器调度程序：
   * O(1)调度程序：多队列调度，每个CPU维护140个优先级队列，每个队列对应一个优先级。（MLFQ，多级队列反馈）
   * 完全公平调度程序（CFS）：使用红黑树和虚拟运行时间跟踪，所有可运行任务按照虚拟运行时间排序插入红黑树，调度器始终选择虚拟运行时间最小的任务。（比例份额，步长调度）
   * BFS调度程序（BFS）：所有CPU使用一个全局任务队列，任务按照优先级插入队列，调度器选择最高优先级的任务分配给空闲CPU。

### 第十三章 抽象：地址空间

1. 地址空间（address space）：是运行的程序看到的系统中内容，是对物理内存的抽象。一个进程的地址空间包含运行的程序的所有内存状态，比如程序的代码、栈（保存函数调用信息、分配空间给局部变量、传递参数和函数返回值）、堆（管理动态分配的、用户管理的内存）、其他（静态初始化的变量）。
2. 虚拟内存系统的目标：
   * 透明：让运行的程序看不见虚拟内存系统的存在。
   * 效率：在空间和时间上尽可能高效。
   * 保护：确保进程受到保护，不会被其他进程影响。

### 第十四章 插叙：内存操作API

1. 在运行一个 C 程序的时候，会有两种内存类型的分配：
   * 栈：申请和释放由编译器进行管理。
   * 堆：由程序员进行显式的分配和回收。
2. `malloc` 调用：传入要申请的堆空间的大小，成功就返回一个指向新申请空间的指针，失败就返回`NULL`。
3. `free` 调用：接受一个由 `malloc` 返回的指针，不需要分配区域的大小，**必须由内存分配库本身记录追踪**。
4. 常见错误：
   * 忘记分配内存，即使用的指针并没有指向一块动态分配的内存区域。
   * 没有分配足够的内存。
   * 忘记初始化分配的内存。
   * 忘记释放内存
   * 在用完之前释放内存
   * 重复释放内存
   * 错误的调用 `free`，即给 `free` 传入的参数不是一个 `malloc` 得到的指针。
5. 系统中实际存在两级内存管理：
   * 第一级由操作系统执行的内存管理，操作系统在进程运行时将内存交给进程，并在进程退出时将其回收。
   * 第二级管理在每个进程中，例如调用 `malloc()` 和 `free()` ，在堆内管理内存。
6. 管理内存的工具：`purify`  `valgrind`。

### 第十五章 机制：地址转换

1. 基于硬件的地址转换，动态重定位，基址加界限机制：每个 `CPU` 需要两个硬件寄存器，**基址寄存器**和**界限寄存器**，使用这种方式，编写和编译程序时假设地址空间从零开始，但是当程序真正运行时，操作系统会决定其在物理内存中的实际加载地址，并将起始地址记录在基址寄存器中。

   > physical address = virtual address(address in program) + base

   界限寄存器确保这个地址在进程地址空间的范围内，从而来确保安全。

2. 操作系统必须记录哪些空闲内存没有使用，以便能够为进程分配内存，有许多数据结构可以用于这项任务，比如**空闲列表（free list）。**

3. 采用动态重定位技术，很容易产生内部碎片，即已经分配的内存单元内部有未使用的空间（即碎片）。（因为此时假设地址空间放在固定大小的槽块中）。

### 第十六章 分段

1. 我们之间假设将所有进程的地址空间完整加载到内存中去，然后通过简单的基址、界限寄存器来进行地址重定位，这样就造成了物理内存空间的浪费，因为堆与栈之间有大量的一些空闲内存，而这些内存无法被其他进程进行使用，造成了浪费。所以采用**分段**的思想，在典型的地址空间里有3个逻辑不同的段：**代码、栈、堆**。我们可以将进程逻辑不同的段放入不同的物理内存段，从而避免栈与堆之间浪费大量的内存空间，所以MMU里面则需要3对基址、界限寄存器。

2. 硬件在进行地址转换的时候，如何知道该地址属于哪个段？如何知道段内的偏移？

   * 显式方式：利用虚拟地址的开头即为来标识不同的段
   * 隐式方式：通过地址产生的方式来判断，比如，如果地址由程序计数器产生，那么地址在代码段，如果基于栈或基址指针，则在栈段，否则在堆段。

3. 当使用分段的方式进行重定位的时候，会出现一些**外部碎片**，分配的内存之间的有一些很小的内存空间没有得到使用，比如系统现在想分配一个20kb的段，系统的内存空间加起来有24kb，但是因为不连续，所以无法进行内存分配，所以可以有以下解决方案：

   * 紧凑物理内存：重新安排原有的段，让已分配的物理内存紧凑起来，但是该操作是内存密集型任务，会占用大量的处理器时间。
   * 利用空闲列表管理算法，试图保留大得的内存块用于后续的分配，但是算法只能减少，不能避免。

4. 分段机制总结：
   好处：

   * 更高效的虚拟内存，避免了内部碎片。
   * 代码共享，可以给一些段加上控制权限，从而来实现共享。

   坏处：

   * 外部碎片
   * 还是无法解决稀疏地址空间，比如有一个很大但是很稀疏的堆，它们在同一个逻辑段里面，整个堆还是必须完整的加载到内存中。

### 第十七章 空闲空间管理

1. 当需要管理的空间被划分为固定大小的单元，就很容易进行管理，但是如果要管理的空闲空间由大小不同的单元构成，管理就变得困难，主要要考虑以下问题：
   * 要满足变长的分配请求，应该如何管理空闲空间？
   * 什么策略可以让碎片最小化？
   * 不同方法的时间、空间开销如何？

2. 要提供的机制：
   * 分割：当用户申请的字节数小于空闲列表的长度时，要将该空闲列表进行分割，一部分返回给用户，一部分留着等待后续使用。
   * 合并：当用户归还内存的时候，不应该只是简单的将该内存加入到空闲列表中，而应当与相邻的内存块进行合并。
   * 追踪已分配空间的大小：在 `free` 函数中并没有传入大小，所以内存分配库要能确定要释放空间的大小，从而将其放回空闲列表。大多数分配程序会在头块中保存一点额外的信息，比如用户要20字节的内存，则会先在内存区域存放相关的数据结构，再将该内存后面的20字节返回给用户，释放的时候则可以通过前面的头块数据来读取相关长度。（做实验发现glibc中malloc中要求8字节对齐，最小分配24个字节，可以使用malloc_usable_size()函数返回实际分配的空间大小，而分配的内存前面16个字节则是头块数据结构，两个size_t类型，因为要求8字节对齐，所以分配的长度肯定是8的倍数，且不少于24个字节，所以64位的最低4位用作标志位）。
   * 嵌入空闲列表：在典型的列表实现中，我们使用 `molloc` 来分配一个节点所需要的内存空间，但是当我们使用一个空闲列表来管理 `malloc` 分配的内存时，则需要在空闲空间本身建立空闲空间列表，通过 `mmap` 系统调用来实现，该系统调用返回一个指针，指向一块空闲内存。
   * 让堆增长：大多数传统的分配程序会在堆空间不足时，向操作系统申请更大的空间，使用 `sbrk` 系统调用，会找到空闲的物理内存页，将他们映射到进程的地址空间中，并返回新的堆的末尾地址，从而增长堆空间的大小。

3. 管理空闲空间的基本策略：

   * 最优匹配：遍历空闲列表，分配大于等于用户要求空间大小的最小空闲内存。
   * 最差匹配：找到最大的空闲块，分割并且满足用户要求的空间大小以后，将剩余的块加入空闲列表。
   * 首次匹配：遍历空闲列表，分配第一个满足用户要求的内存块给用户。
   * 下次匹配：在首次匹配的基础上，维护一个额外的指针，记录上次分配的位置，然后下次分配时从该位置进行遍历。

4. 《Understanding glibc malloc》
   1. `brk` 



### 第18章 分页：介绍
1. 解决空间管理问题：
   * 将空间分割成不同长度的分片，分段。
   * 将空间分割成固定长度的分片，分页。
2. 对于每一个进程，操作系统都需要去记录该进程的每一个虚拟页存放在物理内存中的位置，所以操作系统为每一个进程设计了一个数据结构，称为页表（page table）。页表的作用就是保存虚拟页面与物理页面之间的转化关系，也就是一个虚拟页对应的是哪一个物理页。
3. 虚拟地址：虚拟页面号（virtual page number, VPN）和页内偏移（offset，页的大小即确定便宜的位数）
4. 页表的组织：页表就是一种数据结构，用于将虚拟地址映射到物理地址，比如可以是一个数组，os通过虚拟页号VPN检索数组，找到页表项pte（page table entry），然后再找到对应的物理帧号。除了这个简单的对应关系以外，页表项中还包含：
   * 有效位（valid bit）：用于标记地址转换是否有效，os并不会刚开始就给每个虚拟内存分配一个物理页面，而是可以将一些页面标记为无效，这样等os访问的时候，就会进入os代码，去判断访问是否合法，再去进行内存的分配或者 `segmentation fault`。
   * 保护位（protection bit）：用于标记页面是否可以读取、写入、执行。
   * 存在位（present bit）：用于标记该页面是在物理存储器还是在磁盘上，即这一页面是否已经换出（swapped out），从内存换到磁盘。
   * 脏位（dirty bit）：表明该页被带入内存以后是否进行过修改，用于实现一致性。
   * 参考位（reference bit）：用于追踪页是否被访问，用于确定哪些页受欢迎，因此应该保存在内存中。
5. 要进行地址转换，硬件必须知道当前正在运行的进程的页表的位置。


### 第19章 分页：快速地址转换（TLB）
1. 使用分页机制来实现虚拟内存，就需要将地址空间切分成大量固定大小的单元，并且需要记录这些单元的映射信息，而且这些映射信息一般存储在物理内存中，所以在进行虚拟地址转换的时候，分页逻辑上需要一次额外的内存访问。（去内存空间读取到映射关系，然后再进行内存访问。）
2. 为了加快内存访问，os则需要**硬件**的帮助，即地址转换旁路缓冲存储器（translation-lookaside buffer,TLB），频繁发生的虚拟地址到物理地址转换的硬件缓存。对于每次内存访问，硬件先检查TLB，如果有期望的映射，则不再需要去访问页表。
3. 缓存是计算机系统中提升性能的一个常见手段，其基本思路是利用程序的时间局部性和空间局部性原理。但是当 `TLB` 没有命中的时候，必须有一个东西来处理这种情况，很显然，有以下两种选择：
* 硬件：一般是 cisc 体系架构计算机，有更复杂的指令集。
* 操作系统：risc 体系架构，当 `TLB` 未命中的时候，硬件系统抛出异常，操作系统暂停当前的执行流，提升至内核模式，跳转至对应的陷阱处理程序，也就是说，处理未命中的代码是一段 `os` 代码。
4. 当利用操作系统处理 `TLB` 未命中的时候，有以下细节需要注意：
* 不同于一般的系统调用，当从陷阱处理程序返回以后，执行陷入操作系统之后的那条指令，但是 `TLB` 未命中从系统调用返回以后，应当重复执行刚才未命中的那条指令，所以在陷入 `os` 内核的时候，要根据情况保存不同的 `pc`。
* 要避免无限递归，即陷阱处理程序中也会 `TLB` 未命中。要解决这一问题，可以把陷阱处理程序直接放在物理内存中去，或者在 `TLB` 中保留一些项，记录永远的地址转换，并且将一些项留给陷阱处理程序本身的代码块。
5. `TLB` 中包含的虚拟到物理地址的映射只对当前进程有效，对其他进程是没有意义的。**在上下文切换时，操作系统必须改变页表基址寄存器（PTBR）的值。`PTBR` 中存放的是当前进程页表的物理地址。**


### 第20章 分页：较小的表
1. 每个进程都有自己的页表，如果页表的大小太大，当系统中运行多个进程的时候，那么页表占用的内存就过大了。


### 第20章 分页：较小的表
1. 假设32位地址空间，每个页大小为 4 KB，那么一共有 $2^{32} / 2^{12} = 2^{20} $ 个页表项，每一个页表项为 4 个字节，那么页表就要占 $2 ^ {20} \times 4 = 2 ^ {22} = 4 MB$，这对于内存空间负担太大，所以我们需要一些方法来使得页表的空间变小。一种方法就是缩小页表项的大小，一种方法就是减少页表项的数量，这是两种基本思路。
   * 更大的页：通过增加每个页的大小，在地址空间保持不变的情况下，就可以减少页表项的数量。但是这种方法会造成页内的浪费，因为将某个页加载到内存的时候，可能只使用一小部分。（内存页太大）
   * 分页和分段：我们将内存分为代码、堆、栈，然后在每个段中再进行分页，使用基址寄存器指向保存该段的页表的物理地址，界限寄存器用于指示页表的结尾。这种方法的主要思路在于减少内存中无效的页表，**我们不是为进程的整个地址空间提供单个页表，而是为每个逻辑分段提供一个。**
   * 多级页表：与分页和分段方法思路一样，即**去掉页表中的所有无效区域，而不是将他们都全部保留在内存中**。将页表分成页大小的单元，如果整页的页表项（PTE）无效，就不分配该页的页表。使用页目录来记录。
2. 超越二级页表：
假设地址空间30位，每一页大小是512个字节，也就是说页内偏移需要9位，页号一共则有21位，**构建多级页表的目标是为了让页表的每一部分都放入一个页，这样子就可以通过页目录项来进行索引。**我们假设每个页表项位4个字节，也就是说一页中可以放入128个页表项，那么我们索引页表的时候就需要 7 位（页表的页内偏移），此时还有14（30 - 9 - 7 = 14）位可以用来索引页表，也就是存放页目录项的表，我们的页目录项就一共有 2 ^ 14 个，也就是页目录项要占用 2 ^ 14 * 4 / 512 = 2 ^ 7 = 128 个页，还是很占用内存空间，所以可以再建立一级页表。
```
cpp
1    VPN = (VirtualAddress & VPN_MASK) >> SHIFT
2    (Success, TlbEntry) = TLB_Lookup(VPN)
3    if (Success == True)    // TLB Hit
4        if (CanAccess(TlbEntry.ProtectBits) == True)
5            Offset   = VirtualAddress & OFFSET_MASK
6            PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
7            Register = AccessMemory(PhysAddr)
8        else
9            RaiseException(PROTECTION_FAULT)
10   else                  // TLB Miss
11       // first, get page directory entry
12       PDIndex = (VPN & PD_MASK) >> PD_SHIFT
13       PDEAddr = PDBR + (PDIndex * sizeof(PDE))
14       PDE     = AccessMemory(PDEAddr)
15       if (PDE.Valid == False)
16           RaiseException(SEGMENTATION_FAULT)
17       else
18           // PDE is valid: now fetch PTE from page table
19           PTIndex = (VPN & PT_MASK) >> PT_SHIFT
20           PTEAddr = (PDE.PFN << SHIFT) + (PTIndex * sizeof(PTE))
21           PTE     = AccessMemory(PTEAddr)
22           if (PTE.Valid == False)
23               RaiseException(SEGMENTATION_FAULT)
24           else if (CanAccess(PTE.ProtectBits) == False)
25               RaiseException(PROTECTION_FAULT)
26           else
27               TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
28               RetryInstruction()
```

### 第 21 章 超越物理内存：机制
1. 为什么要超越物理内存，给进程支持巨大的地址空间？
   * 方便和易用性：程序员只需要自然的编写程序，根据需要分配内存，而不必担心数据结构是否有空间进行存储。
   * 多道程序（能够同时运行多个程序，更好的利用机器资源）的出现强烈要求能够换出一些页，因为早期的机器显然不能将所有进程需要的所有内存页同时存放在内存中。
2. 为了使用硬盘上的交换页，我们需要引入一些新的机制，页表项中增加一个**存在位**来表示该页是否存在在物理内存中。
3. 当程序从内存中读取数据会发生什么？

### 第 22 章 超越物理内存：策略
1. 内存中只包含所有页的一个子集，所以可以将内存视为系统中虚拟内存页的缓存。
2. 常见策略：
* 最优策略（理想情况）：每次踢掉最远将来才会访问的页。
* FIFO：先进先出。不具有**栈特征**，增加缓存大小有可能命中率甚至下降。
* 随机：随机选择一个页面换出。
* LRU(最近最少使用) / LFU(最不经常使用)：利用历史信息来决定换出哪些页，一个是频率，如果一个页被访问了很多次，那么他不应该被换出；一个是近期性，越近被访问过的页，也许再次访问的可能性也就越大。

### 第 23 章 VAX/VMS虚拟内存系统
1. 页的按需置零（demand zeroing）：初级实现中，操作系统响应一个请求，在物理内存中找到页，将该页添加到堆中，并将其置零（否则你可以看到其他进程在使用这个页时的内容），然后将其映射到你的地址空间。利用按需置零，页加入地址空间时，os会在页表中放入一个标记页不可访问的条目，如果进程读取或写入页，会向os发送一个陷阱，此时os再进行置零，并且映射到进程的地址空间，从而减少开销，避免一些不会使用的页也进行按需置零。
2. 写时复制(copy on write)：如果os需要将一个页面从一个地址空间复制到另一个地址空间，不是实际复制它，而是将其映射到目标地址空间，并在两个地址空间中将其标记为只读，如果其中一个地址空间确实尝试写入页面，就会陷入os，os此时再分配一个新页面，填充数据。

### 第 26 章 并发：介绍

1. 线程：为当个运行进程提供的抽象。经典观点是一个程序只有一个执行点（一个ip寄存器，用来存放要执行的指令地址），但是多线程程序会有多个执行点（多个pc，每个都用于取指令和执行）。换一个角度看，每一个线程类似于独立的进程，只有一点区别：**线程之间共享地址空间，从而可以访问相同的数据。**每个线程有自己的一组用于计算的寄存器，所以在一个处理器上切换线程，就必须要保存相关信息。对于进程，我们将状态保存到进程控制块（PCB），而对于线程，我们需要一个或多个线程控制块（TCB）。但是，与进程相比，线程之间的上下文切换有一点主要区别：**地址空间保持不变（即不需要切换当前使用的页表）**，进程与线程之间的另一个主要区别在于栈，多线程程序中每一个线程都有一个栈。
2. 原子性：全部或没有。
3. 线程之间的交互：
* 访问共享变量：互斥，为临界区支持原子性。
* A线程需要在B线程执行完以后运行：同步。

### 第 27 章 插叙：线程API
1. 将 `void` 指针作为函数的参数，允许我们传入任何类型的参数；将 `void` 作为返回值，允许线程返回任何类型的结果。
2. `POSIX` 线程提供的锁的重要api：
```c
int pthread_mutex_lock(pthread_mutex_t *mutex);
int pthread_mutex_unlock(pthread_mutex_t *mutex);
//所有的锁在使用的时候都必须正确初始化
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_init(&lock, NULL);
//用完锁进行摧毁
pthread_mutex_destroy();
```
3. **要使用条件变量，必须另外有一个与此条件相关的锁。**因为条件变量也是共享资源，是多个线程可能同时访问的东西，所以要加锁保证互斥。
```c
//调用线程进入休眠状态，等待其他线程发出信号。
int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);
//唤醒某个条件。
int pthread_cond_signal(pthread_cond_t *cond);
```

### 第 28 章 锁
1. 并发编程的基本问题：**原子式的执行一系列指令，但是由于单处理器的中断或者多个线程在多个处理器上并发执行，很难做到。**

2. 评价锁的指标：
* 互斥：能否实现互斥，即阻止多个线程进入临界区。
* 公平性：当锁可用的时候，是否每一个竞争线程有公平的机会抢到锁。
* 性能：使用锁以后增加的时间开销，需要考虑多种场景，如只有一个线程获取释放锁，一个cpu上多个线程竞争锁，多个cpu上多个线程竞争锁。

3. 锁的实现：
* **关闭中断**：为单处理器系统开发，在临界区关闭中断，这样就不会被其他线程进行抢占，从而实现原子操作。这种方法的弊端：
   * 对于开关中断这样的指令，应该是特权级的指令，一般的进程不应该有这个权限，否则很容易出现安全问题，若进程出现死循环，也只能重启系统。
   * 现在基本上都是多处理器，这种方式对多处理器不起作用，因为多处理器中关中断只能影响当前CPU核心，而其他核心仍然可以并行执行代码。多处理器上的并发问题不仅是中断导致的临界区操作不具有原子性，还包括多个线程可能在不同核心同时进入临界区，访问资源。
   * 关闭中断可能导致中断丢失，比如在中断关闭的过程中，磁盘 io 结束，发起的中断将不会被 cpu 响应，所以可能需要一些更复杂的机制来对中断进行保存。
   * 性能较差。
* **原子交换指令**：测试并设置指令（test-and-set instruction），也叫做原子交换指令（atomic exchange），通过标志位来实现锁：
   ```c
   1    typedef struct  lock_t { int flag; } lock_t;
   2
   3    void init(lock_t *mutex) {
   4        // 0 -> lock is available, 1 -> held
   5        mutex->flag = 0;
   6    }
   7
   8    void lock(lock_t *mutex) {
   9        while (mutex->flag == 1) // TEST the flag
   10           ; // spin-wait (do nothing)
   11       mutex->flag = 1;         // now SET it!
   12   }
   13
   14   void unlock(lock_t *mutex) {
   15       mutex->flag = 0;
   16   }
   ```
   但是需要硬件提供一定的支持，否则比如线程一调用 `lock` ，执行到 `while(mutex->flag == 1)` 以后，正准备执行 `mutex->flag = 1` 时，被切到线程二调用 `lock` ，然后再返回，这样就导致线程一二都可以进入临界区，所以硬件提供了一些指令，各个平台上有不同的指令(x86上为 xchg 指令)，这些指令干的事情可以概括如下：
   ```c
   1    int TestAndSet(int *old_ptr, int new) {
   2        int old = *old_ptr; // fetch old value at old_ptr
   3        *old_ptr = new;    // store 'new' into old_ptr
   4        return old;        // return the old value
   5    }
   ```
   测试并设置指令做了下述事情。它返回old_ptr指向的旧值，同时更新为new的新值。当然，关键是这些代码是原子地（atomically）执行。所以我们可以利用该指令来实现 **自旋锁**，仅仅需要将上面的代码修改为：
   ```c
      while(TestAndSet(&lock->flag, 1) == 1);
   ```
   **重点就是在于 `while` 判断的时候原子的进行了值的设置，而不会在对 `flag` 的值进行修改的时候被中断。**
* **比较并交换**：某些系统提供了另一个硬件原语，即比较并交换指令（x86上为 compare-and-exchange），指令伪代码:
   ```c
   1    int CompareAndSwap(int *ptr, int expected, int new) {
   2        int actual = *ptr;
   3        if (actual == expected)
   4            *ptr = new;
   5        return actual;
   6    }
   ```
   该指令会检测 `ptr` 指向的值与 `expected` 的值是否相等，如果相等，则更新 `ptr` 指向的值为新值，否则什么也不做，然后返回旧值。利用该指令，也可以实现一个锁：
   ```c
      while(CompareAndSwap(&lock->flag, 0, 1) == 1);
   ```
   如果 `lock->flag` 指向的值是0，则变为1，并返回0；否则，值是1，返回1。**重点就是在于 `while` 判断的时候原子的进行了值的设置，而不会在对 `flag` 的值进行修改的时候被中断。**
* **链接的加载和条件式存储指令**：例如Mips架构提供了链接的加载(load-linked)和条件式存储(store-conditional)可以配合使用来实现临界区。
   ```c
   1    int LoadLinked(int *ptr) {
   2        return *ptr;
   3    }
   4
   5    int StoreConditional(int *ptr, int value) {
   6        if (no one has updated *ptr since the LoadLinked to this address) {
   7            *ptr = value;
   8            return 1; // success!
   9        } else {
   10           return 0; // failed to update
   11       }
   12   }
   ```
   链接的加载指令从内存中取出一个值放入寄存器，条件式存储指令比较特殊，只有当上一次加载的地址没有被再调用过 `LoadLinked` 才会成功，将值进行修改，否则失败。依据这两条硬件指令，我们也可以实现一个锁：
   ```c
      void init(lock_t *mutex){
         mutex->flag = 0;
      }
      void lock(lock_t *mutex){
         while(1){
            while(LoadLinked(&mutex->flag) == 1);
            if(StoreConditional(&mutex->flag, 1) == 1)
               return;
         }
      }
      void unlock(lock_t *mutex){
         mutex->flag = 0;
      }
   ```
   **重点就是判断标志以后如何可以原子的进行修改**
* **获取并增加**：获取并增加指令(fetch-and-add)，可以原子的返回特定地址的旧值，然后让该值自增一。
   ```c
   1    int FetchAndAdd(int *ptr) {
   2        int old = *ptr;
   3        *ptr = old + 1;
   4        return old;
   5    }
   1    typedef struct  lock_t {
   2        int ticket;
   3        int turn;
   4    } lock_t;
   5
   6    void lock_init(lock_t *lock) {
   7        lock->ticket = 0;
   8        lock->turn   = 0;
   9    }
   10
   11   void lock(lock_t *lock) {
   12       int myturn = FetchAndAdd(&lock->ticket);
   13       while (lock->turn != myturn)
   14           ; // spin
   15   }
   16
   17   void unlock(lock_t *lock) {
   18       FetchAndAdd(&lock->turn);
   19   }
   ```
   相当于每一个线程有一个顺序，当你调用 `lock` 的时候，就会将当前的 `ticket` 赋值给你，然后每次解锁的时候就调用下一个，将 `turn + 1`，只有 `turn == ticket` 的时候，就轮到这个线程持有锁了。

4. 当有 N 个线程在单处理上运行的时候，如果需要一把锁，那么只有一个线程可以持有，然后时间片到了以后，调用别的线程去运行，别的线程只会去尝试获取锁，造成 `cpu` 空转，如果这 `N` 个线程都被调用一次，那么就会浪费 `N - 1` 个时间片，极大的造成性能的浪费。

5. 提高自选锁的性能的方法:
* 主动让出CPU：操作系统提供一种原语，当线程发现自己要进行自旋的时候，主动调用该原语，os 就将该线程从运行态变为就绪态，从而允许其他线程进行运行。（但是上下文切换依然开销很大，而且有可能会有进程饿死，一直得不到调用）
* 使用队列，用休眠替代自旋：为了避免资源浪费以及进程饿死的出现，所以我们应该对**唤醒进程进行显式的控制**，操作系统应该有权力来决定哪一个进程得到锁，Solaris提供了两个系统调用：
   * park()：让调用线程进行休眠。
   * unpark(threadId)：唤醒 threadID 标识的线程。
Linux 下提供了两个系统调用：
   * futex_wait(address, expected)：如果 address 处的值等于 expected，就会让调用线程睡眠，否则，调用立刻返回。
   * futex_wake(address)：唤醒等待队列中的一个线程。


### 第 29 章 基于锁的并发数据结构
1. 通过给数据结构加锁可以使得数据结构**线程安全(thread safe)**。
2. 最简单、最基本的并发数据结构常见的数据模式：加一把锁，在调用函数操作该数据结构时获取锁，从调用返回时释放锁。**如果简单的方法可以正常工作，就不需要精巧的设计。**
3. 并发计数器的设计：通过对计数器递增递减来加锁可以实现正确性，但是性能较差。所以使用一种**懒惰计数器**，对于每一个 CPU，有一个局部计数器，还有一个全局的计数器，每一个计数器都由一把锁来控制，每个线程运行在 CPU 上的时候，可以更新局部计数器，然后在特定的时间间隔以后，再将局部计数器的值同步到全局计数器。时间间隔比较短的时候，性能较差，但是全局与局部差异较小，时间间隔长的时候，性能较好，但是全局与局部差异较大。
4. 并发链表：可以给链表加一把大锁，要操作链表的时候尝试获取锁。可以缩小锁的粒度（即临界区越短越好），比如在给链表插入节点的时候，只需要执行插入操作之前获取锁。
5. **在编码的时候，注意控制流的变化导致函数返回和退出，或者一些错误情况导致函数停止执行，因为很多函数会在开始的时候获取锁、分配内存，或者进行其他一些改变状态的操作，如果错误发生，代码需要在返回前恢复各种状态。**

### 第 30 章 条件变量
1. 互斥并不是并发编程唯一需要的原语，互斥只能保证某几个操作之间是独立的，即 A 发生的时候 B 不会发生， B 发生的时候 A 不会发生，但是很多情况下，线程之间还需要 **同步**，即线程之间发生的先后顺序需要被控制，比如 A 先发生， B 再发生，最简单的情况是利用一个**共享变量**，一个线程不断地去判断这个共享变量的值是否被修改，若被修改，则证明另一个线程执行完毕，但是这样子等待的线程会一直自旋，浪费 CPU 性能，最好的方式是让在等待的时候线程休眠，然后另一个线程执行完毕以后，再对等待的线程进行唤醒。
2. 条件变量：是一个显式队列，当某些执行状态不满足的时候（条件不满足），线程把自己加入队列，等待该条件；当另外某个线程改变了上述状态以后，就可以唤醒一个或多个等待线程，让他们继续执行。
   * wait()：线程睡眠
   * signal()：唤醒等待在某个条件变量上的睡眠线程。
3. 条件变量也是一个共享内存（临界区），多个线程都会对其进行读写，所以需要给其加锁。（hold the lock when calling signal or wait）
4. 生产者/消费者（有界缓冲区）问题：
   * 使用while而不是if：发送信号唤醒线程**只是暗示状态发生了变化，并不会保证就是线程想要的状态**，这是很多系统上信号的语义（Mesa语义），还有一种语义（Hoare）是保证唤醒线程会立刻执行，这种语义下if则不会有问题，但是这种语义实现比较复杂，几乎所有系统采用了Mesa语义。
   * 不能只使用一个条件变量：因为发送信号唤醒线程，具体唤醒哪一个线程取决于等待队列的管理，假设有两个消费线程因为缓冲区为空进行休眠，此时一个生产线程在缓冲区放了东西，然后再放的时候发现缓冲区有东西，所以休眠，此时消费线程1消费缓冲区，然后唤醒了消费线程2，此时消费线程2发现缓冲区没有东西，进行休眠，然后消费线程1执行发现没有东西，休眠，所以此时一个生产线程，两个消费线程都会进行休眠。**信号需要具有指向性。**

5. 覆盖条件：有的时候发送信号唤醒线程的时候，线程被唤醒检查条件发现条件依然不满足，从而继续休眠，但是有些等待的线程条件是满足的，从而就浪费了这一次的唤醒，所以有一种处理方式就是**唤醒所有线程**。


### 第 31 章 信号量
1. 在并发编程中，**同步原语**用于协调多个线程或进程对共享资源进行访问：
   * 控制并发访问：锁，实现互斥
   * 线程间通信：条件变量

   可以使用**信号量**来实现锁和条件变量，换言之，信号量可以作为与同步有关所有工作的单一原语。

2. 信号量有两个关键操作:
   * sem_wait()：信号量的值减少 1，如果信号量的值 < 0 则挂起调用线程。
   * sem_post()：信号量的值增加 1，如果此时有线程等待，则唤醒一个线程。
   **所以当信号量的值为负数的时候，这个值就是等待线程的个数。**

3. 二值信号量（锁）：将信号量的值设置为 1，此时访问临界区的时候调用 `sem_wait()`，出临界区以后调用 `sem_post()` 就可以实现锁的效果。

4. 使用信号量作为条件变量：将信号量的值设置为 0， A 等待 B 执行完成后再执行，那么就可以在 A 中调用 `sem_wait()`，然后在 `B` 中调用 `sem_post()` 。

5. 使用信号量解决生产者/消费者问题：
   * 缓冲区是共享资源，对于缓冲区的操作需要加锁保持原子性。
   * 对于锁的获取，应该是先等待条件变量，条件满足以后再尝试获取锁，如果先获取锁则可能出现死锁。

6. 读者-写者锁：不同的数据结构访问模式可能需要不同类型的锁，比如一个并发链表如果插入节点则需要加锁，但是如果只是读取节点的值，则没必要加锁。
   ```c
   typedef struct _rw_lock_t{
      sem_t lock; //普通的锁，值为 1
      sem_t writelock; // 用于允许一个人写或多个人读
      int readers; //当前在临界区读的个数
   } rwlock_t;
   ```
   写锁与普通的锁一致，但是对于获取读锁时，我们首先获取 lock，然后增加 readers 的数量，如果是第一位读者，同时获取 writelock，然后就可以释放 lock 了；释放读锁的时候，首先获取 lock，然后减少 readers 的数量，如果是最后一位读者，释放 writelock。**此处的 lock 相当于在控制对 readers 的读写，保证其更新是原子的。** 

7. 哲学家就餐问题：打破依赖！！！如果每个人都优先拿左边的叉子，那么可能会出现死锁，我们可以让某个人优先拿自己右手的叉子。

8. 实现信号量：初始化，wait，post
   ```c
   typedef struct _Zem_t{
      int value;
      pthread_cond_t cond;
      pthread_mutex_t lock;
   } Zem_t;

   //init
   void Zem_init(Zem_t *s, int value){
      s->value = value;
      Cond_init(&s->cond);
      Mutex_init(&s->lock);
   }

   //wait
   void Zem_wait(Zem_t *s){
      Mutex_lock(&s->lock);
      while(s->value <= 0)
         Cond_wait(&s->cond, &s->lock);
      s->value--;
      Mutex_unlock(&s->lock);
   }

   //post
   void Zem_post(Zem_t *s){
      Mutex_lock(&s->lock);
      s->value++;
      Cond_signal(&s->cond);
      Mutex_unlock(&s->lock);
   }
   ```
   与上面描述的信号量有点差别，这里的信号量永远不会小于0。

### 第 32 章 常见并发问题
1. 违反原子性缺陷：违反了多次内存访问中**预期的可串行性**，即代码段本意是原子性的，但是在执行过程中并没有强制实现原子性。没有互斥。

2. 违反顺序缺陷：两个内存访问的预期顺序被打破了。没有同步。

3. 产生死锁的四个条件（必要条件）：
   * 互斥：线程对于需要的资源进行互斥的访问。
   * 持有并等待：线程持有了资源，同时又在等待其他资源。
   * 非抢占：线程已经获得的资源不能被其他线程进行抢占。
   * 循环等待：线程之间存在一个环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的。
   要避免死锁，就可以打破以上的任意一个条件。

4. 实际代码中，最常采用的就是让代码不会产生循环等待：
   * 锁的全序：每次都是先申请 A ，再申请 B。
   * 锁的偏序：

5. 在获取多个锁的时候，可以通过锁的地址顺序来获取锁，从而可以避免循环等待。

### 第 33 章 基于事件的并发（进阶）
1. 基于事件的并发：当使用多线程实现并发的时候，一方面很容易忘记加锁、死锁等问题出现，即很难实现正确并发；另一方面，开发者无法控制多线程在某一时刻的调度，程序员创建线程以后就依赖于操作系统的调度。所以有基于事件的并发，即不用线程，同时保证对并发的控制。

2. 事件循环：等待某件事件发生，当它发生时，检查事件类型，然后做少量的工作。
   ```c
   while(1){
      events = getEvents();
      for(e in events)
         processEvent(e);
   }
   ```
   处理程序在处理一个事件的时候，是系统中发生的唯一活动。

3. select()/poll()：检查是否有任何应该关注的进入 I\O。select()检查I/O描述符集合，它们的地址通过readfds、writefds和errorfds传入，分别查看它们中的某些描述符是否已准备好读取，是否准备好写入，或有异常情况待处理。在每个集合中检查前nfds个描述符，即检查描述符集合中从0到nfds-1的描述符。返回时，select()用给定请求操作准备好的描述符组成的子集替换给定的描述符集合。select()返回所有集合中就绪描述符的总数。

### 第 36 章 I/O 设备
1. 操作系统检查设备状态的时候如何避免频繁轮询，从而降低管理设备的 CPU 开销？
   * 利用中断：CPU 不再需要轮询设备，而是向设备发送一个请求，然后就可以让对应进程睡眠，切换执行其他任务，当设备完成了自身操作，会抛出一个硬件中断，引发 CPU 跳转到执行操作系统中预先定义好的中断服务程序。
   * 利用 DMA 进行更高效的数据传送：如果 CPU 参与数据移动，即位编程 I/O(programmed I/O, PIO)，这种方式会将 CPU 的时间浪费在向设备传输数据或从设备传出数据的过程中，所以可以**分离这项工作**，提高 CPU 利用率，即 DMA 技术，直接内存访问。

2. 操作系统与设备之间通信：
   * 使用明确的 I/O 指令，这些指令规定了操作系统将数据发送到特定设备寄存器的方法。
   * 内存映射 I/O，硬件将设备寄存器作为内存地址提供，当需要访问设备的时候，操作系统独读取或者写入到该内存地址，然后应将会将读取/写入转移到设备上。

### 第 37 章 磁盘驱动器
